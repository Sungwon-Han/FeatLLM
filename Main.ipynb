{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c271658",
   "metadata": {},
   "source": [
    "# LLM is a great rule-based feature engineer in few-shot tabular learning\n",
    "## Overview\n",
    "This notebook runs training and inference for few-shot tabular learning task over benchmark datasets. GPT-3.5 model is used in this tutorial.\n",
    "\n",
    "## Overall process\n",
    "* Prepare datasets\n",
    "* Extract rules for prediction from training samples with the help of LLM\n",
    "* Parse rules to the program code and convert data into the binary vector\n",
    "* Train the linear model to predict the likelihood of each class from the binary vector\n",
    "* Make inference with ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df4835c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ba82",
   "metadata": {},
   "source": [
    "## Prepare datasets\n",
    "1. Set dataset and simulation parameters (e.g., # of queries for ensemble, # of training shots, and the random seed)\n",
    "2. Get data and split it into train/test dataset, given simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185c4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "_NUM_QUERY = 5 # Number of ensembles\n",
    "_SHOT = 4 # Number of training shots\n",
    "_SEED = 0 # Seed for fixing randomness\n",
    "_DATA = 'diabetes'\n",
    "_API_KEY = '<PUT YOUR OWN API KEY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53387d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.207</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>176</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.443</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "106            1       96            122              0        0  22.4   \n",
       "91             4      123             80             15      176  32.0   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "106                     0.207   27  \n",
       "91                      0.443   34  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.set_seed(_SEED)\n",
    "df, X_train, X_test, y_train, y_test, target_attr, label_list, is_cat = utils.get_dataset(_DATA, _SHOT, _SEED)\n",
    "X_all = df.drop(target_attr, axis=1)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90de3d",
   "metadata": {},
   "source": [
    "## Extract rules for prediction from training samples with the help of LLM\n",
    "To enable the LLM to extract rules based on a more accurate reasoning path, we guided the problem-solving process to mimic how a person might approach a tabular learning task.   \n",
    "\n",
    "We divided the problem into two sub-tasks for this purpose:   \n",
    "1. Understand the task description and the features provided by the data, inferring the causal relationships beforehand.   \n",
    "2. Use the inferred information and few-shot samples to deduce the prediction rules for each class. This two-step reasoning process prevents the model from identifying spurious correlations in irrelevant columns and assists in focusing on more significant features.   \n",
    "\n",
    "Our prompt comprises three main components as follows:  \n",
    "* Task description\n",
    "* Reasoning instruction\n",
    "* Response instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c63e6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert. Given the task description and the list of features and data examples, you are extracting conditions for each answer class to solve the task.\n",
      "\n",
      "Task: Does this patient have diabetes? Yes or no?\n",
      "\n",
      "\n",
      "Features:\n",
      "- Pregnancies: Number of times pregnant (numerical variable)\n",
      "- Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test (numerical variable)\n",
      "- BloodPressure: Diastolic blood pressure (mm Hg) (numerical variable)\n",
      "- SkinThickness: Triceps skin fold thickness (mm) (numerical variable)\n",
      "- Insulin: -Hour serum insulin (mu U/ml) (numerical variable)\n",
      "- BMI: Body mass index (weight in kg/(height in m)^2) (numerical variable)\n",
      "- DiabetesPedigreeFunction: Diabetes pedigree function (numerical variable)\n",
      "- Age: Age (years) (numerical variable)\n",
      "\n",
      "Examples:\n",
      "Pregnancies is 4. Glucose is 123. BloodPressure is 80. SkinThickness is 15. Insulin is 176. BMI is 32.0. DiabetesPedigreeFunction is 0.443. Age is 34.\n",
      "Answer: no\n",
      "Pregnancies is 1. Glucose is 96. BloodPressure is 122. SkinThickness is 0. Insulin is 0. BMI is 22.4. DiabetesPedigreeFunction is 0.207. Age is 27.\n",
      "Answer: no\n",
      "Pregnancies is 4. Glucose is 117. BloodPressure is 62. SkinThickness is 12. Insulin is 0. BMI is 29.7. DiabetesPedigreeFunction is 0.38. Age is 30.\n",
      "Answer: yes\n",
      "Pregnancies is 9. Glucose is 156. BloodPressure is 86. SkinThickness is 0. Insulin is 0. BMI is 24.8. DiabetesPedigreeFunction is 0.23. Age is 53.\n",
      "Answer: yes\n",
      "\n",
      "\n",
      "Let's first understand the problem and solve the problem step by step.\n",
      "\n",
      "Step 1. Analyze the causal relationship or tendency between each feature and task description based on general knowledge and common sense within a short sentence. \n",
      "\n",
      "Step 2. Based on the above examples and Step 1's results, infer 10 different conditions per answer, following the format below. The condition should make sense, well match examples, and must match the format for [condition] according to value type.\n",
      "\n",
      "Format for Response:\n",
      "10 different conditions for class \"no\":\n",
      "- [Condition]\n",
      "...\n",
      "\n",
      "10 different conditions for class \"yes\":\n",
      "- [Condition]\n",
      "...\n",
      "\n",
      "\n",
      "Format for [Condition]:\n",
      "For the categorical variable only,\n",
      "- [Feature_name] is in [list of Categorical_values]\n",
      "For the numerical variable only,\n",
      "- [Feature_name] (> or >= or < or <=) [Numerical_value]\n",
      "- [Feature_name] is within range of [Numerical_range_start, Numerical_range_end]\n",
      "\n",
      "\n",
      "Answer: \n",
      "Step 1. The relationship between each feature and the task description: \n"
     ]
    }
   ],
   "source": [
    "ask_file_name = './templates/ask_llm.txt'\n",
    "meta_data_name = f\"./data/{_DATA}-metadata.json\"\n",
    "templates, feature_desc = utils.get_prompt_for_asking(\n",
    "    _DATA, X_all, X_train, y_train, label_list, target_attr, ask_file_name, \n",
    "    meta_data_name, is_cat, num_query=_NUM_QUERY\n",
    ")\n",
    "print(templates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee074a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Pregnancies: There is no clear causal relationship between the number of pregnancies and the presence of diabetes. However, it is known that women who have had multiple pregnancies are at a higher risk of developing gestational diabetes.\n",
      "- Glucose: High levels of glucose in the blood are indicative of diabetes. \n",
      "- BloodPressure: There is a correlation between high blood pressure and diabetes, but it is not a definitive indicator.\n",
      "- SkinThickness: There is no direct causal relationship between skin thickness and diabetes. However, individuals with diabetes may have thicker skin due to certain metabolic changes.\n",
      "- Insulin: High levels of insulin may indicate the presence of diabetes, especially if accompanied by high glucose levels. \n",
      "- BMI: High BMI is associated with an increased risk of developing type 2 diabetes. \n",
      "- DiabetesPedigreeFunction: This function calculates the genetic risk of diabetes based on family history. Higher values indicate a higher risk. \n",
      "- Age: The risk of developing diabetes increases with age. \n",
      "\n",
      "Step 2. Inferred conditions based on examples and Step 1's results:\n",
      "\n",
      "10 different conditions for class \"no\":\n",
      "- Glucose < 100\n",
      "- BloodPressure <= 80\n",
      "- Insulin <= 50\n",
      "- BMI < 25\n",
      "- DiabetesPedigreeFunction < 0.2\n",
      "- Age < 40\n",
      "- Pregnancies <= 2\n",
      "- SkinThickness <= 10\n",
      "- Glucose < 110 and BMI < 30\n",
      "- Age < 30 and Insulin <= 20\n",
      "\n",
      "10 different conditions for class \"yes\":\n",
      "- Glucose >= 120\n",
      "- BloodPressure > 80\n",
      "- Insulin > 100\n",
      "- BMI >= 30\n",
      "- DiabetesPedigreeFunction >= 0.3\n",
      "- Age >= 50\n",
      "- Pregnancies > 5\n",
      "- SkinThickness > 20\n",
      "- Glucose >= 140 and BMI >= 35\n",
      "- Age >= 40 and Insulin > 50\n"
     ]
    }
   ],
   "source": [
    "_DIVIDER = \"\\n\\n---DIVIDER---\\n\\n\"\n",
    "_VERSION = \"\\n\\n---VERSION---\\n\\n\"\n",
    "\n",
    "rule_file_name = f'./rules/rule-{_DATA}-{_SHOT}-{_SEED}.out'\n",
    "if os.path.isfile(rule_file_name) == False:\n",
    "    results = utils.query_gpt(templates, _API_KEY, max_tokens=1500, temperature=0.5)\n",
    "    with open(rule_file_name, 'w') as f:\n",
    "        total_rules = _DIVIDER.join(results)\n",
    "        f.write(total_rules)\n",
    "else:\n",
    "    with open(rule_file_name, 'r') as f:\n",
    "        total_rules_str = f.read().strip()\n",
    "        results = total_rules_str.split(_DIVIDER)\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a316dc4",
   "metadata": {},
   "source": [
    "## Parse rules to the program code and convert data into the binary vector\n",
    "\n",
    "We utilize the rules generated in the previous stage to transform each sample into a binary vector. These vectors are created for each answer class, indicating whether the sample satisfies the rules associated with that class. However, since the rules generated by the LLM are based on natural language, parsing the text into program code is required for automatic data transformation.  \n",
    "\n",
    "To address the challenges of parsing noisy text, instead of building complex program code, we leverage the LLM itself. We include the function name, input and output descriptions, and inferred rules in the prompt, then input it into the LLM. The generated code is executed using Pythonâ€™s exec() function along with the provided function name to perform data conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c7e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_rules = utils.parse_rules(results, label_list)\n",
    "\n",
    "saved_file_name = f'./rules/function-{_DATA}-{_SHOT}-{_SEED}.out'    \n",
    "if os.path.isfile(saved_file_name) == False:\n",
    "    function_file_name = './templates/ask_for_function.txt'\n",
    "    fct_strs_all = []\n",
    "    for parsed_rule in tqdm(parsed_rules):\n",
    "        fct_templates = utils.get_prompt_for_generating_function(\n",
    "            parsed_rule, feature_desc, function_file_name\n",
    "        )\n",
    "        fct_results = utils.query_gpt(fct_templates, _API_KEY, max_tokens=1500, temperature=0)\n",
    "        fct_strs = [fct_txt.split('<start>')[1].split('<end>')[0].strip() for fct_txt in fct_results]\n",
    "        fct_strs_all.append(fct_strs)\n",
    "\n",
    "    with open(saved_file_name, 'w') as f:\n",
    "        total_str = _VERSION.join([_DIVIDER.join(x) for x in fct_strs_all])\n",
    "        f.write(total_str)\n",
    "else:\n",
    "    with open(saved_file_name, 'r') as f:\n",
    "        total_str = f.read().strip()\n",
    "        fct_strs_all = [x.split(_DIVIDER) for x in total_str.split(_VERSION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ae86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get function names and strings\n",
    "fct_names = []\n",
    "fct_strs_final = []\n",
    "for fct_str_pair in fct_strs_all:\n",
    "    fct_pair_name = []\n",
    "    if 'def' not in fct_str_pair[0]:\n",
    "        continue\n",
    "\n",
    "    for fct_str in fct_str_pair:\n",
    "        fct_pair_name.append(fct_str.split('def')[1].split('(')[0].strip())\n",
    "    fct_names.append(fct_pair_name)\n",
    "    fct_strs_final.append(fct_str_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192a5980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def extracting_features_no(df_input):\n",
      "    df_output = pd.DataFrame()\n",
      "    \n",
      "    df_output['Pregnancies'] = df_input['Pregnancies'].apply(lambda x: 1 if x <= 2 else 0)\n",
      "    df_output['Glucose'] = df_input['Glucose'].apply(lambda x: 1 if x < 100 else 0)\n",
      "    df_output['BloodPressure'] = df_input['BloodPressure'].apply(lambda x: 1 if x <= 80 else 0)\n",
      "    df_output['SkinThickness'] = df_input['SkinThickness'].apply(lambda x: 1 if x <= 10 else 0)\n",
      "    df_output['Insulin'] = df_input['Insulin'].apply(lambda x: 1 if x <= 50 else 0)\n",
      "    df_output['BMI'] = df_input['BMI'].apply(lambda x: 1 if x < 25 else 0)\n",
      "    df_output['DiabetesPedigreeFunction'] = df_input['DiabetesPedigreeFunction'].apply(lambda x: 1 if x < 0.2 else 0)\n",
      "    df_output['Age'] = df_input['Age'].apply(lambda x: 1 if x < 40 else 0)\n",
      "    \n",
      "    df_output['Glucose_BMI'] = df_input.apply(lambda x: 1 if x['Glucose'] < 110 and x['BMI'] < 30 else 0, axis=1)\n",
      "    df_output['Age_Insulin'] = df_input.apply(lambda x: 1 if x['Age'] < 30 and x['Insulin'] <= 20 else 0, axis=1)\n",
      "    \n",
      "    return df_output\n"
     ]
    }
   ],
   "source": [
    "print(fct_strs_final[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c1e34",
   "metadata": {},
   "source": [
    "### Convert to binary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07cb55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_list, X_train_all_dict, X_test_all_dict = utils.convert_to_binary_vectors(fct_strs_final, fct_names, label_list, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea38b2b",
   "metadata": {},
   "source": [
    "## Train the linear model to predict the likelihood of each class from the binary vector\n",
    "When given the rules for each class and a sample, a simple method to measure the class likelihood of the sample is to count how many rules of each class it satisfies (i.e., the sum of the binary vector per class). However, not all rules carry the same importance, necessitating learning their significance from training samples.    \n",
    "  \n",
    "We aimed to train this importance using a basic linear model without bias, applied to each class's binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cbee21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_model(nn.Module):\n",
    "    def __init__(self, X):\n",
    "        super(simple_model, self).__init__()\n",
    "        self.weights = nn.ParameterList([nn.Parameter(torch.ones(x_each.shape[1] , 1) / x_each.shape[1]) for x_each in X])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_total_score = []\n",
    "        for idx, x_each in enumerate(x):\n",
    "            x_score = x_each @ torch.clamp(self.weights[idx], min=0)\n",
    "            x_total_score.append(x_score)\n",
    "        x_total_score = torch.cat(x_total_score, dim=-1)\n",
    "        return x_total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38036b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train_now, label_list, shot):\n",
    "    criterion = nn.CrossEntropyLoss()                \n",
    "    if shot // len(label_list) == 1:\n",
    "        model = simple_model(X_train_now)\n",
    "        opt = Adam(model.parameters(), lr=1e-2)\n",
    "        for _ in range(200):                    \n",
    "            opt.zero_grad()\n",
    "            outputs = model(X_train_now)\n",
    "            preds = outputs.argmax(dim=1).numpy()\n",
    "            acc = (np.array(y_train_num) == preds).sum() / len(preds)\n",
    "            if acc == 1:\n",
    "                break\n",
    "            loss = criterion(outputs, torch.tensor(y_train_num))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    else:\n",
    "        if shot // len(label_list) <= 2:\n",
    "            n_splits = 2\n",
    "        else:\n",
    "            n_splits = 4\n",
    "\n",
    "        kfold = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "        model_list = []\n",
    "        for fold, (train_ids, valid_ids) in enumerate(kfold.split(X_train_now[0], y_train_num)):\n",
    "            model = simple_model(X_train_now)\n",
    "            opt = Adam(model.parameters(), lr=1e-2)\n",
    "            X_train_now_fold = [x_train_now[train_ids] for x_train_now in X_train_now]\n",
    "            X_valid_now_fold = [x_train_now[valid_ids] for x_train_now in X_train_now]\n",
    "            y_train_fold = y_train_num[train_ids]\n",
    "            y_valid_fold = y_train_num[valid_ids]\n",
    "\n",
    "            max_acc = -1\n",
    "            for _ in range(200):                    \n",
    "                opt.zero_grad()\n",
    "                outputs = model(X_train_now_fold)\n",
    "                loss = criterion(outputs, torch.tensor(y_train_fold))\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                valid_outputs = model(X_valid_now_fold)\n",
    "                preds = valid_outputs.argmax(dim=1).numpy()\n",
    "                acc = (np.array(y_valid_fold) == preds).sum() / len(preds)\n",
    "                if max_acc < acc:\n",
    "                    max_acc = acc \n",
    "                    final_model = copy.deepcopy(model)\n",
    "                    if max_acc >= 1:\n",
    "                        break\n",
    "            model_list.append(final_model)\n",
    "\n",
    "        sdict = model_list[0].state_dict()\n",
    "        for key in sdict:\n",
    "            sdict[key] = torch.stack([model.state_dict()[key] for model in model_list], dim=0).mean(dim=0)\n",
    "\n",
    "        model = simple_model(X_train_now)\n",
    "        model.load_state_dict(sdict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9a9ff5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7615740740740741\n",
      "AUC: 0.7524074074074074\n",
      "AUC: 0.7947222222222222\n",
      "AUC: 0.8035185185185185\n",
      "AUC: 0.793425925925926\n",
      "Ensembled AUC: 0.8006481481481481\n"
     ]
    }
   ],
   "source": [
    "test_outputs_all = []\n",
    "multiclass = True if len(label_list) > 2 else False\n",
    "y_train_num = np.array([label_list.index(k) for k in y_train])\n",
    "y_test_num = np.array([label_list.index(k) for k in y_test])\n",
    "\n",
    "for i in executable_list:\n",
    "    X_train_now = list(X_train_all_dict[i].values())\n",
    "    X_test_now = list(X_test_all_dict[i].values())\n",
    "    \n",
    "    # Train\n",
    "    trained_model = train(X_train_now, label_list, _SHOT)\n",
    "\n",
    "    # Evaluate\n",
    "    test_outputs = trained_model(X_test_now).detach().cpu()\n",
    "    test_outputs = F.softmax(test_outputs, dim=1).detach()\n",
    "    result_auc = utils.evaluate(test_outputs.numpy(), y_test_num, multiclass=multiclass)\n",
    "    print(\"AUC:\", result_auc)\n",
    "    test_outputs_all.append(test_outputs)\n",
    "test_outputs_all = np.stack(test_outputs_all, axis=0)\n",
    "ensembled_probs = test_outputs_all.mean(0)\n",
    "result_auc = utils.evaluate(ensembled_probs, y_test_num, multiclass=multiclass)\n",
    "print(\"Ensembled AUC:\", result_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
